{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Demo\n",
    "\n",
    "This file serves as a comprehensive overview of the implementation of the Multi-Layer Perceptron (MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from mlp.activations import Sigmoid, Linear, ReLU, Softmax\n",
    "from mlp.losses import MeanSquaredError, CrossEntropy\n",
    "from mlp.optimizers import Optimizer\n",
    "from mlp.mlp import MLP, MLPLayersBuilder\n",
    "from mlp.constants import SEED\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier  # For comparison\n",
    "\n",
    "# Profiling\n",
    "from cProfile import Profile\n",
    "from pstats import SortKey, Stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Problem\n",
    "\n",
    "- non-linear decision boundary\n",
    "\n",
    "<img src=\"xor.png\" alt=\"XOR\" width=\"400px\">\n",
    "\n",
    "(Credit: Aniruddha Karajgi - [How Neural Networks Solve the XOR Problem](https://towardsdatascience.com/how-neural-networks-solve-the-xor-problem-59763136bdd7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "y = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Gradient Descent\n",
    "\n",
    "- with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron\n",
      " - Layer 0: Input with Linear activation and 2 neurons\n",
      " - Layer 1: Dense with Sigmoid activation and 5 neurons\n",
      " - Layer 2: Dense with Sigmoid activation and 1 neurons\n",
      "Epoch 1/10000 | Loss: [0.50015956]\n",
      "Epoch 1001/10000 | Loss: [0.49999688]\n",
      "Epoch 2001/10000 | Loss: [0.49998976]\n",
      "Epoch 3001/10000 | Loss: [0.49997352]\n",
      "Epoch 4001/10000 | Loss: [0.49991528]\n",
      "Epoch 5001/10000 | Loss: [0.49932249]\n",
      "Epoch 6001/10000 | Loss: [0.43331883]\n",
      "Epoch 7001/10000 | Loss: [0.15882902]\n",
      "Epoch 8001/10000 | Loss: [0.0210697]\n",
      "Epoch 9001/10000 | Loss: [0.00880619]\n",
      "[[0.04675456]\n",
      " [0.95023446]\n",
      " [0.950628  ]\n",
      " [0.05898119]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=MeanSquaredError(),\n",
    "          n_epochs=10_000,\n",
    "          learning_rate=0.9,\n",
    "          print_frequency=1_000,\n",
    "          batch_size=X.shape[0])\n",
    "print(mlp)\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with two hidden layers (learning time increases, LR must also be set higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000 | Loss: [0.50063226]\n",
      "Epoch 2001/20000 | Loss: [0.49999995]\n",
      "Epoch 4001/20000 | Loss: [0.49999988]\n",
      "Epoch 6001/20000 | Loss: [0.49999978]\n",
      "Epoch 8001/20000 | Loss: [0.49999961]\n",
      "Epoch 10001/20000 | Loss: [0.49999923]\n",
      "Epoch 12001/20000 | Loss: [0.49999802]\n",
      "Epoch 14001/20000 | Loss: [0.49998582]\n",
      "Epoch 16001/20000 | Loss: [0.00036631]\n",
      "Epoch 18001/20000 | Loss: [0.00010878]\n",
      "[[0.0059796 ]\n",
      " [0.99496663]\n",
      " [0.99467777]\n",
      " [0.00606359]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=MeanSquaredError(),\n",
    "          n_epochs=20_000,\n",
    "          learning_rate=20,\n",
    "          print_frequency=2_000,\n",
    "          batch_size=X.shape[0])\n",
    "mlp.fit(X, y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with cross-entropy (more appropriate loss yields more accurate results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000 | Loss: 1.4067851199793036\n",
      "Epoch 1001/10000 | Loss: 1.3862286448305612\n",
      "Epoch 2001/10000 | Loss: 0.09770425849200409\n",
      "Epoch 3001/10000 | Loss: 0.015338943583119637\n",
      "Epoch 4001/10000 | Loss: 0.007875949782712728\n",
      "Epoch 5001/10000 | Loss: 0.005227523662116129\n",
      "Epoch 6001/10000 | Loss: 0.003888745652833281\n",
      "Epoch 7001/10000 | Loss: 0.0030856721208831657\n",
      "Epoch 8001/10000 | Loss: 0.00255223684094427\n",
      "Epoch 9001/10000 | Loss: 0.0021730116011985786\n",
      "[[0.00106148]\n",
      " [0.99900329]\n",
      " [0.99910735]\n",
      " [0.0011468 ]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          n_epochs=10_000,\n",
    "          learning_rate=0.9,\n",
    "          print_frequency=1_000,\n",
    "          batch_size=X.shape[0])\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with cross-entropy and two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000 | Loss: 1.3163776701063878\n",
      "Epoch 2001/20000 | Loss: 1.3862939592350552\n",
      "Epoch 4001/20000 | Loss: 1.3862949375159754\n",
      "Epoch 6001/20000 | Loss: 1.3862961577317217\n",
      "Epoch 8001/20000 | Loss: 1.3862982396128865\n",
      "Epoch 10001/20000 | Loss: 1.3863026869540414\n",
      "Epoch 12001/20000 | Loss: 1.386307854173105\n",
      "Epoch 14001/20000 | Loss: 0.001685145353581686\n",
      "Epoch 16001/20000 | Loss: 0.00042766392481325766\n",
      "Epoch 18001/20000 | Loss: 0.00022687644638765556\n",
      "[[1.87916076e-04]\n",
      " [9.99924926e-01]\n",
      " [9.99924883e-01]\n",
      " [6.94430793e-05]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          n_epochs=20_000,\n",
    "          learning_rate=5,\n",
    "          print_frequency=2_000,\n",
    "          batch_size=X.shape[0])\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Stochastic Gradient Descent\n",
    "\n",
    "- we can notice a significant reduction in learning time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 | Loss: 1.6714886430374924\n",
      "Epoch 101/1000 | Loss: 1.3650505844525338\n",
      "Epoch 201/1000 | Loss: 1.1129079741919605\n",
      "Epoch 301/1000 | Loss: 0.31537916754668416\n",
      "Epoch 401/1000 | Loss: 0.04218939371778174\n",
      "Epoch 501/1000 | Loss: 0.021854677011071036\n",
      "Epoch 601/1000 | Loss: 0.014538872185703725\n",
      "Epoch 701/1000 | Loss: 0.010807560612850186\n",
      "Epoch 801/1000 | Loss: 0.008559904725761808\n",
      "Epoch 901/1000 | Loss: 0.00706486227628214\n",
      "[[0.00221109]\n",
      " [0.9970236 ]\n",
      " [0.99697411]\n",
      " [0.00523788]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          n_epochs=1_000,\n",
    "          learning_rate=0.9,\n",
    "          print_frequency=100,\n",
    "          batch_size=1)\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Stochastic Gradient Descent with Momentum\n",
    "\n",
    "- again a significant reduction in learning time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Loss: 0.8961455735130106\n",
      "Epoch 11/100 | Loss: 1.2533403574210196\n",
      "Epoch 21/100 | Loss: 1.1675980006302695\n",
      "Epoch 31/100 | Loss: 0.886864352843159\n",
      "Epoch 41/100 | Loss: 0.8110626725144197\n",
      "Epoch 51/100 | Loss: 0.5712211272437716\n",
      "Epoch 61/100 | Loss: 0.09101475544093689\n",
      "Epoch 71/100 | Loss: 0.03786048573408496\n",
      "Epoch 81/100 | Loss: 0.024727643261475016\n",
      "Epoch 91/100 | Loss: 0.018424634668718878\n",
      "[[0.00705071]\n",
      " [0.99255338]\n",
      " [0.99253324]\n",
      " [0.01193854]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          optimizer=Optimizer.SGD_MOMENTUM,\n",
    "          n_epochs=100,\n",
    "          learning_rate=0.5,\n",
    "          print_frequency=10,\n",
    "          batch_size=1,\n",
    "          momentum=0.9)\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAGrad Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000 | Loss: 1.4626224155806873\n",
      "Epoch 1001/10000 | Loss: 1.3873309186595386\n",
      "Epoch 2001/10000 | Loss: 1.3863562324303977\n",
      "Epoch 3001/10000 | Loss: 1.3229542803125782\n",
      "Epoch 4001/10000 | Loss: 1.1275731991225544\n",
      "Epoch 5001/10000 | Loss: 1.0112479974960298\n",
      "Epoch 6001/10000 | Loss: 0.9507905436284405\n",
      "Epoch 7001/10000 | Loss: 0.8464785107348616\n",
      "Epoch 8001/10000 | Loss: 0.665893381829449\n",
      "Epoch 9001/10000 | Loss: 0.47828222132909143\n",
      "[[0.03621863]\n",
      " [0.84495366]\n",
      " [0.84538056]\n",
      " [0.16930388]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          optimizer=Optimizer.ADAGRAD,\n",
    "          n_epochs=10000,\n",
    "          learning_rate=0.05,\n",
    "          print_frequency=1000,\n",
    "          batch_size=1,\n",
    "          momentum=0.9,\n",
    "          shuffle=True)\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp Optimizer\n",
    "\n",
    "- note that the initial cache `(Layer._weight_v & Layer._bias_v)` is initialized to `0` (Tensorflow uses `0`, Pytorch uses `1`)\n",
    "    - due to this decision, the learning rate must be set to a lower value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 | Loss: 1.4646204715448579\n",
      "Epoch 101/1000 | Loss: 0.864252842853261\n",
      "Epoch 201/1000 | Loss: 0.8499606271877937\n",
      "Epoch 301/1000 | Loss: 0.8447740392373606\n",
      "Epoch 401/1000 | Loss: 0.8421744885468587\n",
      "Epoch 501/1000 | Loss: 0.8406749740472536\n",
      "Epoch 601/1000 | Loss: 0.8396413848587594\n",
      "Epoch 701/1000 | Loss: 0.020630150958757434\n",
      "Epoch 801/1000 | Loss: 0.004501011888488405\n",
      "Epoch 901/1000 | Loss: 0.002190113940384297\n",
      "[[3.28362961e-04]\n",
      " [9.99328577e-01]\n",
      " [9.99344572e-01]\n",
      " [1.87349269e-02]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          optimizer=Optimizer.RMSPROP,\n",
    "          n_epochs=1000,\n",
    "          learning_rate=0.05,\n",
    "          print_frequency=100,\n",
    "          batch_size=1,\n",
    "          momentum=0.9)\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 | Loss: 1.4448380950968098\n",
      "Epoch 101/1000 | Loss: 1.3850383090736456\n",
      "Epoch 201/1000 | Loss: 1.3852650591116098\n",
      "Epoch 301/1000 | Loss: 1.2150826084504405\n",
      "Epoch 401/1000 | Loss: 0.6393716795037153\n",
      "Epoch 501/1000 | Loss: 0.19141023764266474\n",
      "Epoch 601/1000 | Loss: 0.066097244413905\n",
      "Epoch 701/1000 | Loss: 0.03314648804662379\n",
      "Epoch 801/1000 | Loss: 0.019897991653148824\n",
      "Epoch 901/1000 | Loss: 0.013153088740467493\n",
      "[[0.00170673]\n",
      " [0.99537612]\n",
      " [0.99539795]\n",
      " [0.00784896]]\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(2)\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(5, Sigmoid())\\\n",
    "    .add_dense(1, Sigmoid())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          optimizer=Optimizer.ADAM,\n",
    "          n_epochs=1000,\n",
    "          learning_rate=0.01,\n",
    "          print_frequency=100,\n",
    "          batch_size=1,\n",
    "          momentum=0.9)\n",
    "mlp.fit(X,y)\n",
    "print(mlp.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset\n",
    "\n",
    "### SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 | Loss: 122.91449639267151\n",
      "Epoch 101/500 | Loss: 35.06830216300894\n",
      "Epoch 201/500 | Loss: 16.515480014895942\n",
      "Epoch 301/500 | Loss: 10.997864307437471\n",
      "Epoch 401/500 | Loss: 8.747593837531937\n",
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "\n",
    "X = data.data\n",
    "y = data.target.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y,test_size=0.25, random_state=SEED, stratify=y)\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False).fit(y_train)\n",
    "y_train = ohe.transform(y_train)\n",
    "y_test = ohe.transform(y_test)\n",
    "\n",
    "mms = MinMaxScaler().fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(4)\\\n",
    "    .add_dense(10, Sigmoid())\\\n",
    "    .add_dense(3, Softmax())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          optimizer=Optimizer.SGD_MOMENTUM,\n",
    "          n_epochs=500,\n",
    "          learning_rate=0.01,\n",
    "          print_frequency=100,\n",
    "          batch_size=8,\n",
    "          momentum=0.9,\n",
    "          shuffle=False)\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true=ohe.inverse_transform(y_test).T[0],\n",
    "                                  y_pred=np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99, 0.01, 0.  ],\n",
       "       [0.  , 0.92, 0.08],\n",
       "       [0.01, 0.99, 0.  ],\n",
       "       [0.  , 0.98, 0.02],\n",
       "       [0.99, 0.01, 0.  ],\n",
       "       [0.  , 0.96, 0.03],\n",
       "       [0.  , 0.43, 0.57],\n",
       "       [0.  , 0.01, 0.99],\n",
       "       [0.  , 0.02, 0.98],\n",
       "       [0.  , 0.01, 0.99]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('First 10 predictions:')\n",
    "y_pred.round(2)[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn implementation\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,),  # Number of units in the hidden layer\n",
    "    activation='logistic',  # Sigmoid activation for the hidden layer\n",
    "    solver='sgd',  # Stochastic Gradient Descent\n",
    "    max_iter=500,  # Number of epochs\n",
    "    learning_rate_init=0.5,\n",
    "    momentum=0.9,\n",
    "    random_state=42,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_one_hot = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true=ohe.inverse_transform(y_test).T[0],\n",
    "                                  y_pred=np.argmax(y_pred_one_hot, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 | Loss: 122.39550140647741\n",
      "Epoch 101/1000 | Loss: 12.341061873161818\n",
      "Epoch 201/1000 | Loss: 7.0985408458733\n",
      "Epoch 301/1000 | Loss: 5.815926382614126\n",
      "Epoch 401/1000 | Loss: 5.230317150056784\n",
      "Epoch 501/1000 | Loss: 4.884673764719647\n",
      "Epoch 601/1000 | Loss: 4.653043718285834\n",
      "Epoch 701/1000 | Loss: 4.484943715656308\n",
      "Epoch 801/1000 | Loss: 4.355734765046648\n",
      "Epoch 901/1000 | Loss: 4.25174120642312\n",
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "layers = MLPLayersBuilder()\\\n",
    "    .add_input(4)\\\n",
    "    .add_dense(10, Sigmoid())\\\n",
    "    .add_dense(3, Softmax())\\\n",
    "    .build()\n",
    "mlp = MLP(layers,\n",
    "          loss_function=CrossEntropy(),\n",
    "          optimizer=Optimizer.ADAM,\n",
    "          n_epochs=1000,\n",
    "          learning_rate=0.01,\n",
    "          print_frequency=100,\n",
    "          batch_size=16,\n",
    "          momentum=0.9)\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true=ohe.inverse_transform(y_test).T[0],\n",
    "                                  y_pred=np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1084840638154925\n",
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,),  # Number of units in the hidden layer\n",
    "    activation='logistic',  # Sigmoid activation for the hidden layer\n",
    "    solver='adam',  # Stochastic Gradient Descent\n",
    "    max_iter=1000,  # Number of epochs\n",
    "    learning_rate_init=0.01,\n",
    "    momentum=0.9,\n",
    "    random_state=42,\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_one_hot = mlp.predict(X_test)\n",
    "\n",
    "print(\"Loss:\", mlp.best_loss_)\n",
    "print(\"Accuracy:\", accuracy_score(y_true=ohe.inverse_transform(y_test).T[0],\n",
    "                                  y_pred=np.argmax(y_pred_one_hot, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo():\n",
    "    layers = MLPLayersBuilder()\\\n",
    "                .add_input(4)\\\n",
    "                .add_dense(10, Sigmoid())\\\n",
    "                .add_dense(3, Softmax())\\\n",
    "                .build()\n",
    "    mlp = MLP(layers,\n",
    "            loss_function=CrossEntropy(),\n",
    "            optimizer=Optimizer.SGD_MOMENTUM,\n",
    "            n_epochs=10_000,\n",
    "            learning_rate=0.01,\n",
    "            print_frequency=1_000,\n",
    "            batch_size=8,\n",
    "            momentum=0.9,\n",
    "            shuffle=False)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_true=ohe.inverse_transform(y_test).T[0],\n",
    "                                    y_pred=np.argmax(y_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000 | Loss: 122.91449639267151\n",
      "Epoch 1001/10000 | Loss: 5.544500233816098\n",
      "Epoch 2001/10000 | Loss: 4.509193578863244\n",
      "Epoch 3001/10000 | Loss: 4.10527220264018\n",
      "Epoch 4001/10000 | Loss: 3.8728374558054828\n",
      "Epoch 5001/10000 | Loss: 3.718829683253311\n",
      "Epoch 6001/10000 | Loss: 3.608919951260028\n",
      "Epoch 7001/10000 | Loss: 3.526448931972931\n",
      "Epoch 8001/10000 | Loss: 3.462159883645847\n",
      "Epoch 9001/10000 | Loss: 3.410465374150089\n",
      "Accuracy: 0.9210526315789473\n",
      "         25484857 function calls in 30.441 seconds\n",
      "\n",
      "   Ordered by: call count\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1680000    0.359    0.000    0.532    0.000 enum.py:769(__hash__)\n",
      "  1680000    0.173    0.000    0.173    0.000 {built-in method builtins.hash}\n",
      "  1400283    0.184    0.000    0.184    0.000 {built-in method builtins.isinstance}\n",
      "  1120305    3.078    0.000    3.078    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  1120004    0.354    0.000    1.126    0.000 {built-in method builtins.next}\n",
      "  1120001    0.154    0.000    0.154    0.000 {built-in method builtins.issubclass}\n",
      "  1120000    0.406    0.000    0.772    0.000 _ufunc_config.py:452(_no_nep50_warning)\n",
      "   700042    0.111    0.000    0.111    0.000 {built-in method builtins.getattr}\n",
      "   560304    0.075    0.000    0.075    0.000 {method 'items' of 'dict' objects}\n",
      "   560302    0.293    0.000    0.293    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "   560302    0.751    0.000    2.736    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "   560011    0.092    0.000    0.092    0.000 {built-in method numpy.asanyarray}\n",
      "   560001    0.440    0.000    0.523    0.000 contextlib.py:102(__init__)\n",
      "   560001    0.242    0.000    0.782    0.000 contextlib.py:130(__enter__)\n",
      "   560001    0.340    0.000    0.926    0.000 contextlib.py:139(__exit__)\n",
      "   560001    0.271    0.000    0.794    0.000 contextlib.py:279(helper)\n",
      "   560001    1.038    0.000    1.222    0.000 _methods.py:67(_count_reduce_items)\n",
      "   560001    3.143    0.000    8.628    0.000 _methods.py:101(_mean)\n",
      "   560001    0.103    0.000    0.103    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "   560000    0.085    0.000    0.085    0.000 fromnumeric.py:3380(_mean_dispatcher)\n",
      "   560000    0.616    0.000    9.243    0.000 fromnumeric.py:3385(mean)\n",
      "   560000    0.186    0.000    0.186    0.000 {method 'set' of '_contextvars.ContextVar' objects}\n",
      "   560000    0.181    0.000    0.181    0.000 {method 'reset' of '_contextvars.ContextVar' objects}\n",
      "   420290    0.065    0.000    0.065    0.000 multiarray.py:741(dot)\n",
      "   420145    2.178    0.000    2.178    0.000 activations.py:17(apply)\n",
      "   420000    0.077    0.000    0.077    0.000 layers.py:53(activations)\n",
      "   280290    1.530    0.000    5.139    0.000 layers.py:91(forward)\n",
      "   280157    0.044    0.000    0.044    0.000 fromnumeric.py:2172(_sum_dispatcher)\n",
      "   280157    0.295    0.000    1.484    0.000 fromnumeric.py:2177(sum)\n",
      "   280145    1.837    0.000    5.289    0.000 activations.py:33(apply)\n",
      "   280145    0.047    0.000    0.047    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "   280145    0.282    0.000    1.877    0.000 fromnumeric.py:2692(max)\n",
      "   280007    0.086    0.000    0.165    0.000 {method 'get' of 'dict' objects}\n",
      "   280000    0.041    0.000    0.041    0.000 layers.py:29(gradient_w)\n",
      "   280000    0.075    0.000    0.075    0.000 layers.py:33(gradient_w)\n",
      "   280000    0.038    0.000    0.038    0.000 layers.py:37(gradient_b)\n",
      "   280000    0.075    0.000    0.075    0.000 layers.py:41(gradient_b)\n",
      "   280000    0.042    0.000    0.042    0.000 layers.py:49(weighted_inputs)\n",
      "   280000    0.891    0.000    4.202    0.000 layers.py:97(apply_gradients)\n",
      "   280000    2.613    0.000    2.693    0.000 layers.py:119(_sgd_momentum)\n",
      "   140147    0.057    0.000    0.057    0.000 {built-in method builtins.min}\n",
      "   140145    0.181    0.000    5.351    0.000 mlp.py:79(_forward)\n",
      "   140145    0.030    0.000    0.030    0.000 layers.py:66(forward)\n",
      "   140042    0.019    0.000    0.019    0.000 {built-in method builtins.len}\n",
      "   140013    0.093    0.000    0.623    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "   140010    0.023    0.000    0.023    0.000 fromnumeric.py:2096(_clip_dispatcher)\n",
      "   140010    0.116    0.000    0.739    0.000 fromnumeric.py:2100(clip)\n",
      "   140010    0.424    0.000    0.424    0.000 _methods.py:90(_clip)\n",
      "   140010    0.077    0.000    0.502    0.000 {method 'clip' of 'numpy.ndarray' objects}\n",
      "   140000    0.490    0.000    1.897    0.000 activations.py:20(apply_derivative)\n",
      "   140000    1.156    0.000    1.918    0.000 losses.py:22(apply_derivative)\n",
      "   140000    0.490    0.000    2.984    0.000 activations.py:38(apply_derivative)\n",
      "   140000    1.788    0.000    8.365    0.000 mlp.py:173(_update_hidden_gradients)\n",
      "   140000    2.255    0.000   24.682    0.000 mlp.py:86(_backpropagate)\n",
      "      156    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "      110    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       33    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "       24    0.000    0.000    0.000    0.000 iostream.py:519(_is_master_process)\n",
      "       24    0.000    0.000    0.001    0.000 iostream.py:546(_schedule_flush)\n",
      "       24    0.000    0.000    0.002    0.000 iostream.py:624(write)\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "       24    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "       21    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
      "       19    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
      "       19    0.000    0.000    0.000    0.000 _config.py:24(_get_threadlocal_config)\n",
      "       19    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       18    0.000    0.000    0.000    0.000 inspect.py:2690(kind)\n",
      "       17    0.000    0.000    0.000    0.000 _config.py:32(get_config)\n",
      "       17    0.000    0.000    0.000    0.000 _array_api.py:227(__getattr__)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       15    0.000    0.000    0.000    0.000 multiarray.py:153(concatenate)\n",
      "       15    0.000    0.000    0.000    0.000 _base.py:1461(issparse)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "       14    0.000    0.000    0.000    0.000 _array_api.py:289(get_namespace)\n",
      "       11    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\n",
      "       11    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "       11    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
      "       11    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:546(is_set)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:1095(_wait_for_tstate_lock)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:1149(is_alive)\n",
      "       11    0.001    0.000    0.001    0.000 socket.py:621(send)\n",
      "       11    0.000    0.000    0.000    0.000 iostream.py:137(_event_pipe)\n",
      "       11    0.000    0.000    0.001    0.000 iostream.py:258(schedule)\n",
      "       11    0.000    0.000    0.005    0.000 mlp.py:161(predict)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "       11    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
      "       10    0.000    0.000    0.000    0.000 losses.py:16(apply)\n",
      "       10    0.000    0.000    0.000    0.000 _ufunc_config.py:33(seterr)\n",
      "       10    0.000    0.000    0.000    0.000 _ufunc_config.py:132(geterr)\n",
      "       10    0.000    0.000    0.000    0.000 _param_validation.py:260(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 _array_api.py:170(_check_device_cpu)\n",
      "       10    0.000    0.000    0.000    0.000 _array_api.py:247(asarray)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
      "        9    0.000    0.000    0.000    0.000 inspect.py:2678(name)\n",
      "        9    0.000    0.000    0.000    0.000 _array_api.py:70(_is_numpy_namespace)\n",
      "        9    0.000    0.000    0.000    0.000 _array_api.py:360(_asarray_with_order)\n",
      "        8    0.000    0.000    0.000    0.000 multiarray.py:85(empty_like)\n",
      "        8    0.000    0.000    0.000    0.000 multiarray.py:1080(copyto)\n",
      "        8    0.000    0.000    0.000    0.000 numeric.py:63(_zeros_like_dispatcher)\n",
      "        8    0.000    0.000    0.000    0.000 numeric.py:67(zeros_like)\n",
      "        7    0.000    0.000    0.000    0.000 _param_validation.py:102(make_constraint)\n",
      "        7    0.000    0.000    0.000    0.000 validation.py:581(_ensure_no_complex_data)\n",
      "        7    0.000    0.000    0.000    0.000 validation.py:591(_check_estimator_name)\n",
      "        7    0.000    0.000    0.000    0.000 validation.py:639(_is_extension_array_dtype)\n",
      "        7    0.000    0.000    0.000    0.000 validation.py:644(check_array)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:2682(default)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)\n",
      "        5    0.000    0.000    0.000    0.000 inspect.py:2960(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 _ufunc_config.py:430(__enter__)\n",
      "        5    0.000    0.000    0.000    0.000 _ufunc_config.py:435(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 validation.py:330(_num_samples)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:63(_recreate_cm)\n",
      "        4    0.000    0.000    0.000    0.000 contextlib.py:76(inner)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:358(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 enum.py:670(__new__)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2628(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 arraysetops.py:125(_unpack_tuple)\n",
      "        4    0.000    0.000    0.000    0.000 arraysetops.py:133(_unique_dispatcher)\n",
      "        4    0.000    0.000    0.000    0.000 arraysetops.py:138(unique)\n",
      "        4    0.000    0.000    0.000    0.000 arraysetops.py:323(_unique1d)\n",
      "        4    0.000    0.000    0.000    0.000 _param_validation.py:73(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {numpy.random._generator.default_rng}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {function SeedSequence.generate_state at 0x0000020A63248040}\n",
      "        3    0.000    0.000    0.000    0.000 inspect.py:2997(parameters)\n",
      "        3    0.000    0.000    0.000    0.000 _param_validation.py:292(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 _param_validation.py:524(is_satisfied_by)\n",
      "        3    0.000    0.000    0.000    0.000 validation.py:267(_is_arraylike)\n",
      "        3    0.000    0.000    0.000    0.000 validation.py:272(_is_arraylike_not_scalar)\n",
      "        3    0.000    0.000    0.000    0.000 _array_api.py:75(isdtype)\n",
      "        3    0.000    0.000    0.000    0.000 _array_api.py:87(_isdtype_single)\n",
      "        3    0.000    0.000    0.000    0.000 _array_api.py:282(isdtype)\n",
      "        3    0.000    0.000    0.000    0.000 layers.py:12(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:277(isfunction)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:1855(isscalar)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:195(_reshape_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:200(reshape)\n",
      "        2    0.000    0.000    0.000    0.000 _config.py:50(set_config)\n",
      "        2    0.000    0.000    0.000    0.000 _config.py:196(config_context)\n",
      "        2    0.000    0.000    0.000    0.000 mlp.py:34(add_dense)\n",
      "        2    0.000    0.000    0.000    0.000 _param_validation.py:602(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 validation.py:404(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 validation.py:393(check_consistent_length)\n",
      "        2    0.000    0.000    0.000    0.000 validation.py:1192(column_or_1d)\n",
      "        2    0.000    0.000    0.000    0.000 _array_api.py:82(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 _array_api.py:261(unique_values)\n",
      "        2    0.000    0.000    0.000    0.000 _array_api.py:267(reshape)\n",
      "        2    0.000    0.000    0.000    0.000 multiclass.py:124(is_multilabel)\n",
      "        2    0.000    0.000    0.000    0.000 multiclass.py:223(type_of_target)\n",
      "        2    0.000    0.000    0.000    0.000 layers.py:72(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 layers.py:78(set_input)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'standard_normal' of 'numpy.random._generator.Generator' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:66(get_annotations)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:632(_is_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:612(unwrap)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2274(_signature_from_function)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2369(_signature_from_callable)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2770(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2831(apply_defaults)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2911(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2989(from_callable)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3041(_bind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3172(bind)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3243(signature)\n",
      "        1    0.000    0.000    0.000    0.000 cProfile.py:50(create_stats)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:107(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:117(init)\n",
      "        1    0.000    0.000    0.000    0.000 pstats.py:136(load_stats)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:669(result_type)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1136(_argmax_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1140(argmax)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:47(_sum)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:55(_any)\n",
      "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:426(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 function_base.py:393(_average_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 function_base.py:398(average)\n",
      "        1    0.348    0.348   30.440   30.440 mlp.py:128(fit)\n",
      "        1    0.000    0.000    0.000    0.000 mlp.py:58(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 mlp.py:39(build)\n",
      "        1    0.000    0.000    0.000    0.000 mlp.py:29(add_input)\n",
      "        1    0.000    0.000    0.000    0.000 mlp.py:26(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:26(validate_parameter_constraints)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:196(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:202(<dictcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 _param_validation.py:183(wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:296(is_satisfied_by)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:306(is_satisfied_by)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:583(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:591(is_satisfied_by)\n",
      "        1    0.000    0.000    0.000    0.000 _array_api.py:12(_check_array_api_dispatch)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:92(_assert_all_finite)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1398(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1366(_is_fitted)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1404(check_is_fitted)\n",
      "        1    0.000    0.000    0.000    0.000 _encoders.py:902(_compute_transformed_categories)\n",
      "        1    0.000    0.000    0.000    0.000 _encoders.py:925(_remove_dropped_categories)\n",
      "        1    0.000    0.000    0.000    0.000 _encoders.py:1109(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _encoders.py:1115(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _encoders.py:1071(inverse_transform)\n",
      "        1    0.000    0.000    0.000    0.000 _classification.py:57(_check_targets)\n",
      "        1    0.000    0.000    0.000    0.000 _classification.py:135(_weighted_sum)\n",
      "        1    0.000    0.000    0.000    0.000 _classification.py:144(accuracy_score)\n",
      "        1    0.000    0.000   30.441   30.441 2299497758.py:1(demo)\n",
      "        1    0.000    0.000    0.000    0.000 layers.py:63(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://realpython.com/python-profiling/\n",
    "\n",
    "with Profile() as profile:\n",
    "    demo()\n",
    "    Stats(profile)\\\n",
    "      .strip_dirs()\\\n",
    "      .sort_stats(SortKey.CALLS)\\\n",
    "      .print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
